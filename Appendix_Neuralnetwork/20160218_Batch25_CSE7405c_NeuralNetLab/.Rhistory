# the net output
# BELOW CODE FROM LINE # 131 TO 142 IS TO GIVE USER A BETTER UNDERSTANDING OF THE LOGIC
# IMPLEMENTED FOR THIS SOLUTION
# NET OUTPUT @ hidden layer
hid_net_1 = In_node_1 * wt_1 + In_node_2 * wt_2 + wt_bNd_1 * bias_node_1
hid_net_2 = In_node_1 * wt_3 + In_node_2 * wt_4 + wt_bNd_1 * bias_node_1
# OUTPUT after implementing sigmoid function to the net output @ hidden layer
hid_out_1 = 1/(1+ (1/exp(hid_net_1)))
hid_out_2 = 1/(1+ (1/exp(hid_net_2)))
#NET FINAL OUTPUT
netO_node = hid_out_1 * wt_5 + hid_out_2*wt_6 + bias_node_2 * wt_bNd_2
# FINAL OUTPUT after implementing sigmoid function
outO_node = 1/(1+ (1/exp(netO_node)))
cat("epoch : ", count-1, "\n")
#############################################################################
#  With initial random weights as mentioned below the Output is
#  given as the Initial target output.
#############################################################################
cat("W1 : ", wt_1,", W2 : ", wt_2,", W3 : ", wt_3,", W4 : ", wt_4,", W5 : ", wt_5,", W6 : ", wt_6, "\n")
cat("Initial Target Output ", outO_node, "\n")
########################################################################################################
#### Backward propagation starts from line # 105 where the in each iteration / epoch weight adjustment
# will be taken care by  first calculating the conttribution of each weight to the new result and
# then adjusting the weights bith initialized learning rate
########################################################################################################
while(round(out_Node - forwardPropOutput$outPut,3) > .0049){
# WEIGHT ADJUSTMENT for WT_5
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden1
target = out_Node
weightContibution_W5 <- hiddenLayerWeightcontrib(target, OutHidden, output)
adjustedWeights_w5 <- adjustedWeights(weightContibution_W5, lrngRate, wt_5)
wt_5 = adjustedWeights_w5
# WEIGHT ADJUSTMENT for WT_6
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden2
target = out_Node
weightContibution_W6 <- hiddenLayerWeightcontrib(target, OutHidden, output)
adjustedWeights_w6 <- adjustedWeights(weightContibution_W6, lrngRate, wt_6)
wt_6 = adjustedWeights_w6
# WEIGHT ADJUSTMENT for WT_1
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden1
target = out_Node
inputNodew1 = In_node_1
hiddenNodew1 = wt_5
#((output - target)*(output*(1-output))*hiddenNodew1*(OutHidden*(1-OutHidden))*(inputNodew1))
weightContibution_W1 <- inputLayerWeightContrib(target, OutHidden, output,inputNodew1,hiddenNodew1)
adjustedWeights_w1 <- adjustedWeights(weightContibution_W1, lrngRate, wt_1)
wt_1 = adjustedWeights_w1
# WEIGHT ADJUSTMENT for WT_2
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden1
target = out_Node
inputNodew2 = In_node_2
hiddenNodew2 = wt_5
weightContibution_W2 <- inputLayerWeightContrib(target, OutHidden, output,inputNodew1,hiddenNodew2)
adjustedWeights_w2 <- adjustedWeights(weightContibution_W2, lrngRate, wt_2)
wt_2 = adjustedWeights_w2
# WEIGHT ADJUSTMENT for WT_3
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden2
target = out_Node
inputNodew3 = In_node_1
hiddenNodew3 = wt_6
weightContibution_W3 <- inputLayerWeightContrib(target, OutHidden, output,inputNodew1,hiddenNodew3)
adjustedWeights_w3 <- adjustedWeights(weightContibution_W3, lrngRate, wt_3)
wt_3 = adjustedWeights_w3
# WEIGHT ADJUSTMENT for WT_4
output = forwardPropOutput$outPut
OutHidden = forwardPropOutput$OutHidden2
target = out_Node
inputNodew4 = In_node_2
hiddenNodew4 = wt_6
weightContibution_W4 <- inputLayerWeightContrib(target, OutHidden, output,inputNodew1,hiddenNodew4)
adjustedWeights_w4 <- adjustedWeights(weightContibution_W4, lrngRate, wt_4)
wt_4 = adjustedWeights_w4
# Calculating the output with new adjusted weights
forwardPropOutput = forward_Propagation(In_node_1, In_node_2, bias_node_1, wt_1,
wt_2,wt_3,wt_4, wt_bNd_1, bias_node_2,
wt_5, wt_6, wt_bNd_2)
cat("epoch #: ", count, "\n")
count = count + 1
cat("W1 : ", wt_1,", W2 : ", wt_2,", W3 : ", wt_3,", W4 : ", wt_4,", W5 : ", wt_5,", W6 : ", wt_6, "\n")
totErroredOutput <- getTotalError(out_Node, forwardPropOutput$outPut)
cat("Target Output ", forwardPropOutput$outPut, "\n")
}
wt_bNd_1
wt_bNd_2
str(preprocTrainData)
# setting the working directory
rm(list=ls(all=TRUE))
# Set working directory
setwd("D:/naveen/Bigdata - hadoop and related/AnalyticalEdgeEdX/DataSets/3_Store_data")
##########################################################
## Library ###############################################
##########################################################
library(data.table)
library(h2o)
library(lubridate)
##########################################################
## Reading the data ######################################
##########################################################
cat("reading the train and test data (with data.table) \n")
trainData <- fread(file = "train.csv", sep = ",")
testData <- fread(file = "test.csv", sep = ",")
store <- fread("store.csv",stringsAsFactors = T)
str(trainData)
summary(trainData)
preprocessTrainData <- function(ppData){
tempData <- ppData
tempData$DayOfWeek <- as.factor(tempData$DayOfWeek)
tempData$Open <- as.factor(tempData$Open)
tempData$Promo <- as.factor(tempData$Promo)
tempData$StateHoliday <- as.factor(tempData$StateHoliday)
tempData$SchoolHoliday <- as.factor(tempData$SchoolHoliday)
tempData$date <- day(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$month <- month(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$year <-  year(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$date <- as.factor(tempData$date)
tempData$month <- as.factor(tempData$month)
tempData$year <- as.factor(tempData$year)
tempData$logSales <- log1p(tempData$Sales)
return(tempData)
}
preprocessTestData <- function(ppData){
tempData <- ppData
tempData$DayOfWeek <- as.factor(tempData$DayOfWeek)
tempData$Open <- as.factor(tempData$Open)
tempData$Promo <- as.factor(tempData$Promo)
tempData$StateHoliday <- as.factor(tempData$StateHoliday)
tempData$SchoolHoliday <- as.factor(tempData$SchoolHoliday)
tempData$date <- day(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$month <- month(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$year <-  year(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$date <- as.factor(tempData$date)
tempData$month <- as.factor(tempData$month)
tempData$year <- as.factor(tempData$year)
return(tempData)
}
preprocTrainData <- preprocessTrainData(trainData)
preProcTestData <- preprocessTestData(testData)
str(preprocTrainData)
ggplot2(preprocTrainData,aes(Store,logSales))
ggplot(preprocTrainData,aes(Store,logSales))
install.packages("ggplot2")
# setting the working directory
rm(list=ls(all=TRUE))
# Set working directory
setwd("D:/naveen/Bigdata - hadoop and related/AnalyticalEdgeEdX/DataSets/3_Store_data")
##########################################################
## Library ###############################################
##########################################################
library(data.table)
library(h2o)
library(lubridate)
##########################################################
## Reading the data ######################################
##########################################################
cat("reading the train and test data (with data.table) \n")
trainData <- fread(file = "train.csv", sep = ",")
testData <- fread(file = "test.csv", sep = ",")
store <- fread("store.csv",stringsAsFactors = T)
str(trainData)
summary(trainData)
preprocessTrainData <- function(ppData){
tempData <- ppData
tempData$DayOfWeek <- as.factor(tempData$DayOfWeek)
tempData$Open <- as.factor(tempData$Open)
tempData$Promo <- as.factor(tempData$Promo)
tempData$StateHoliday <- as.factor(tempData$StateHoliday)
tempData$SchoolHoliday <- as.factor(tempData$SchoolHoliday)
tempData$date <- day(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$month <- month(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$year <-  year(as.POSIXlt(tempData$Date, format="%d-%m-%Y"))
tempData$date <- as.factor(tempData$date)
tempData$month <- as.factor(tempData$month)
tempData$year <- as.factor(tempData$year)
tempData$logSales <- log1p(tempData$Sales)
return(tempData)
}
preprocessTestData <- function(ppData){
tempData <- ppData
tempData$DayOfWeek <- as.factor(tempData$DayOfWeek)
tempData$Open <- as.factor(tempData$Open)
tempData$Promo <- as.factor(tempData$Promo)
tempData$StateHoliday <- as.factor(tempData$StateHoliday)
tempData$SchoolHoliday <- as.factor(tempData$SchoolHoliday)
tempData$date <- day(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$month <- month(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$year <-  year(as.POSIXlt(tempData$Date, format="%Y-%m-%d"))
tempData$date <- as.factor(tempData$date)
tempData$month <- as.factor(tempData$month)
tempData$year <- as.factor(tempData$year)
return(tempData)
}
preprocTrainData <- preprocessTrainData(trainData)
ggplot(preprocTrainData,aes(Store,logSales))
library(ggplot)
library(ggplot2)
ggplot(preprocTrainData,aes(Store,logSales))
ggplot(preprocTrainData,aes(Store,logSales)) + geom_point()
ggplot(preprocTrainData,aes(Store,logSales)) + geom_bar()
ggplot(preprocTrainData,aes(logSales,Store)) + geom_point()
ggplot(preprocTrainData[1:10000,],aes(logSales,Store)) + geom_point()
ggplot(preprocTrainData[1:10000,],aes(Store, logSales)) + geom_point()
ggplot(preprocTrainData[1:10000,],aes(Sales, logSales)) + geom_point()
str(preprocTrainData)
ggplot(preprocTrainData[1:10000,],aes(Sales, Store)) + geom_point()
ggplot(preprocTrainData[1:10000,],aes(Store, Sales)) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, Sales)) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, Sales)) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, logSales)) + geom_point()
which(preprocTrainData$Sales < 0)
preprocTrainData[which(preprocTrainData$Sales < 0),]
preprocTrainData[which(preprocTrainData$Sales <= 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0),]
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0 & Customers = 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0 && Customers = 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0 & Customers == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0 && Customers == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales <= 0 && preprocTrainData$Customers == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
which(preprocTrainData$Customers == 0)
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == 0, preprocTrainData$Sales == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == 0 & preprocTrainData$Sales == 0),]
preprocTrainData[which(preprocTrainData$Sales < 0),]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == "0" & preprocTrainData$Sales == 0),]
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == "0" & preprocTrainData$Sales == 0 &
preprocTrainData$Date == "1" & preprocTrainData$month == "1"),]
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == "0" & preprocTrainData$Sales == 0 &
preprocTrainData$Date == 1 & preprocTrainData$month == 1),]
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == "0" & preprocTrainData$Sales == 0 &
preprocTrainData$date == 1 & preprocTrainData$month == 1),]
ZeroSaleData
ggplot(preprocTrainData[1:100000,],aes(Store, logSales)) + geom_point(color="Date")
ggplot(preprocTrainData[1:100000,],aes(Store, logSales)) + geom_point(color="firebrick")
ggplot(preprocTrainData[1:100000,],aes(Store, logSales)) + geom_point(color="blue")
ggplot(preprocTrainData[1:100000,],aes(Store, logSales,colour ="Date")) + geom_point(color="blue")
ggplot(preprocTrainData[1:100000,],aes(Store, logSales,colour ="Date")) + geom_point()
unique(ZeroSaleData$Date)
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Customers == "0" & preprocTrainData$Sales == 0),]
unique(ZeroSaleData$Date)
str(preprocTrainData)
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, Sales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(month, Sales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(month, mean(Sales),colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(month, Customers,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Customers, Sales,colour ="Date")) + geom_point()
max(preprocTrainData$Customers)
ggplot(preprocTrainData[1:100000,],aes(Customers, logSales,colour ="Date")) + geom_point()
ZeroSaleData
ZeroSaleData[1:100,]
ZeroSaleData[1:50,]
ZeroSaleData[51:100,]
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales == 0 & preprocTrainData$Open == 1),]
ZeroSaleData
nrow(ZeroSaleData)
ZeroSaleData
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales == 0),]
ZeroSaleData
nrow(ZeroSaleData)
ZeroSaleData <- preprocTrainData[which(preprocTrainData$Sales == 0 & preprocTrainData$Open == 1),]
ZeroSaleData
nrow(ZeroSaleData) # there are 172871 entries
ggplot(preprocTrainData[1:100000,],aes(Promo, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(StateHoliday, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(logSales,colour ="StateHoliday")) + geom_histogram()
ggplot(preprocTrainData[1:100000,],aes(logSales,colour ="DayOfWeek")) + geom_histogram()
ggplot(preprocTrainData[1:100000,],aes(logSales,DayOfWeek,colour ="DayOfWeek")) + geom_bar()
ggplot(preprocTrainData[1:100000,],aes(logSales,DayOfWeek)) + geom_bar()
ggplot(preprocTrainData[1:100000,],aes(logSales,DayOfWeek)) + geom_bar(stat = "identity", aes(fill = type))
ggplot(preprocTrainData[1:100000,],aes(logSales,DayOfWeek)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, logSales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, Sales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, Sales)) + geom_bar()
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, Sales)) + geom_bar(stat = "identity")
, aes(fill = DayOfWeek)
ggplot(preprocTrainData[1:100000,],aes(DayOfWeek, Sales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity", aes(fill = month))
ggplot(preprocTrainData[1:100000,],aes(year, Sales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(year, Sales)) + geom_bar(stat = "identity", aes(fill = month))
unique(preprocTrainData$month)
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity")
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "bin")
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity") + scale_x_discrete(drop=FALSE)
ggplot(preprocTrainData[1:100000,],aes(date, Sales)) + geom_bar(stat = "identity", aes(fill = date))
gplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity", aes(fill = month))
gglot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity", aes(fill = month))
ggplot(preprocTrainData[1:100000,],aes(month, Sales)) + geom_bar(stat = "identity", aes(fill = month))
unique(preprocTrainData[1:100000,]$month)
unique(preprocTrainData[1:100000,]$Date)
str(preprocTrainData)
ggplot(preprocTrainData[1:100000,],aes(Store, Sales)) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, Sales)) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Store, logSales,colour ="Date")) + geom_point()
ggplot(preprocTrainData[1:100000,],aes(Customers, logSales,colour ="Date")) + geom_point()
date
ggplot(preprocTrainData[1:100000,],aes(date, Sales)) + geom_bar(stat = "identity", aes(fill = date))
ggplot(preprocTrainData[1:100000,],aes(date, Sales)) + geom_bar(stat = "identity", aes(fill = DayOfWeek))
ggplot(preprocTrainData[1:100000,],aes(date, Sales)) + geom_bar(stat = "identity")
ggplot(preprocTrainData[1:100000,],aes(year, Sales)) + geom_bar(stat = "identity", aes(fill = month))
ggplot(preprocTrainData[1:100000,],aes(year, Sales)) + geom_bar(stat = "identity")
ggplot(preprocTrainData,aes(year, Sales)) + geom_bar(stat = "identity")
ggplot(preprocTrainData, aes(x = Sales)) + geom_dotplot()
x= seq(1,length(preprocTrainData$Sales))
# Ploting the Sales
x
ggplot(preprocTrainData, aes(x=x,y=Sales)) + geom_point()
setwd("D:/naveen/Bigdata - hadoop and related/ActivitiesRepo/20161225_Batch22_CSE7405c_NeuralNetLab/20161225_CSE7405c_Batch22_NeuralNetLab")
rm(list=ls(all=TRUE))
setwd("D:/naveen/Bigdata - hadoop and related/ActivitiesRepo/20161225_Batch22_CSE7405c_NeuralNetLab/20161225_CSE7405c_Batch22_NeuralNetLab")
data = read.csv(file="UniversalBank.csv", header=TRUE, sep=",")
str(data)
summary(data)
data$Education = as.ordered(data$Education)
data$ID = as.factor(data$ID)
data$ZIP.Code = as.factor(data$ZIP.Code)
str(data)
data = subset(data , select = -c(ID, ZIP.Code))
library(dummies)
library(dummies)
education = dummy(data$Education)
education
head(education)
?rm(education)
# Build Neural Network for classification using neuralnet library.
rm(list=ls(all=TRUE))
# Set the working directory
setwd("D:/naveen/Bigdata - hadoop and related/ActivitiesRepo/20161225_Batch22_CSE7405c_NeuralNetLab/20161225_CSE7405c_Batch22_NeuralNetLab")
# Importing "UniversalBank.csv" files's data into R dataframe using read.csv function.
data = read.csv(file="UniversalBank.csv", header=TRUE, sep=",")
# Understand the structure the summary of the data using str and summary R commands
str(data)
# Using subset remove 'ID' and 'ZIP.Code' columns from  the data
data = subset(data , select = -c(ID, ZIP.Code))
str(data)
# Convert all the variables to appropriate type
#   To numeric using as.numeric()
#   To categoical using as.factor()
#   To ordinal using as.factor() with ordered argument set to TRUE or using as.ordered()
data$Education = as.ordered(data$Education)
str(data)
# R NN library takes only numeric attribues as input
# Convert all categorical and ordinal attributes to numeric using appropriate technique. Hint: dummies
# Convert "Education" categorical attribute to numeric using dummy function in dummies R library
# Drop actual Education attribute from orginal data set
# Add created dummy Education variables to orginal data set
library(dummies)
education = dummy(data$Education)
head(education)
data  = subset(data, select=-c(Education))
str(data)
data  = cbind(data, education)
str(data)
(education)
rm(education)
library(vegan)
independent_Variables = decostand(independent_Variables, "range")
data  = data.frame(independent_Variables, Personal.Loan = target_Variable)
rm(independent_Variables, target_Variable)
str(data)
independent_Variables = decostand(independent_Variables, "range")
data  = data.frame(independent_Variables, Personal.Loan = target_Variable)
target_Variable = data$Personal.Loan
independent_Variables = subset(data, select = -c(Personal.Loan))
library(vegan)
independent_Variables = decostand(independent_Variables, "range")
data  = data.frame(independent_Variables, Personal.Loan = target_Variable)
rm(independent_Variables, target_Variable)
str(data)
set.seed(123)
num_Records = nrow(data )
train_Index = sample(1:num_Records, round(num_Records * 0.6, digits = 0))
train_Data = data [train_Index,]
test_Data = data [-train_Index,]
rm(train_Index, num_Records, data)
table(train_Data$Personal.Loan)
table(test_Data$Personal.Loan)
library(neuralnet)
formula = as.formula(paste("Personal.Loan ~",
paste(setdiff(names(train_Data),"Personal.Loan"),
collapse = " + ")))
paste("Personal.Loan ~",
paste(setdiff(names(train_Data),"Personal.Loan"),
collapse = " + "))
library(neuralnet)
install.packages("neuralnet")
neuralnet
library(neuralnet)
formula = as.formula(paste("Personal.Loan ~",
paste(setdiff(names(train_Data),"Personal.Loan"),
collapse = " + ")))
nn = neuralnet(formula, data=train_Data, hidden=2)
out = cbind(nn$covariate, nn$net.result[[1]])
out
nn$covariate
nn$net.result[[1]]
dimnames(out) = list(NULL, c("Age","Experience",
"Income","Family",
"CCAvg","Mortgage",
"Securities.Account",
"CD.Account","Online",
"CreditCard","Education1",
"Education2","Education3",
"nn_Output"))
out
head(out)
rm(out)
nn
plot(nn)
predicted = factor(ifelse(nn$net.result[[1]] > 0.5, 1, 0))
predicted
conf_Matrix = table(train_Data$Personal.Loan, predicted)
conf_Matrix
recall = (conf_Matrix[2,2] / (conf_Matrix[2,1] + conf_Matrix[2,2])) * 100
recall
test_Data_No_Target = subset(test_Data, select=-c(Personal.Loan))
nn_predict = compute(nn, covariate= test_Data_No_Target)
nn_predict$net.result
predicted = factor(ifelse(nn_predict$net.result > 0.5, 1, 0))
conf_Matrix = table(test_Data$Personal.Loan, predicted)
recall = (conf_Matrix[2,2]/(conf_Matrix[2,1]+conf_Matrix[2,2]))*100
recall
rm(nn_predict, predicted, conf_Matrix, recall)
rm(test_Data, train_Data, nn)
rm(list=ls(all=TRUE))
setwd("D:/naveen/Bigdata - hadoop and related/ActivitiesRepo/20161225_Batch22_CSE7405c_NeuralNetLab/20161225_CSE7405c_Batch22_NeuralNetLab")
data = read.csv(file="UniversalBank.csv", header=TRUE, sep=",")
str(data)
data = subset(data , select = -c(ID, ZIP.Code))
str(data)
data$Education = as.ordered(data$Education)
str(data)
library(dummies)
education = dummy(data$Education)
head(education)
data  = subset(data, select=-c(Education))
str(data)
data  = cbind(data, education)
rm(education)
str(data)
target_Variable = data$Personal.Loan
independent_Variables = subset(data, select = -c(Personal.Loan))
library(vegan)
independent_Variables = decostand(independent_Variables, "range")
data  = data.frame(independent_Variables, Personal.Loan = target_Variable)
independent_Variables = decostand(independent_Variables, "range")
data  = data.frame(independent_Variables, Personal.Loan = target_Variable)
rm(independent_Variables, target_Variable)
str(data)
set.seed(123)
num_Records = nrow(data )
train_Index = sample(1:num_Records, round(num_Records * 0.6, digits = 0))
train_Data = data [train_Index,]
test_Data = data [-train_Index,]
rm(train_Index, num_Records, data)
table(train_Data$Personal.Loan)
table(test_Data$Personal.Loan)
library(neuralnet)
formula = as.formula(paste("Personal.Loan ~",
paste(setdiff(names(train_Data),"Personal.Loan"),
collapse = " + ")))
formula
nn = neuralnet(formula, data=train_Data, hidden=2)
out = cbind(nn$covariate, nn$net.result[[1]])
out
dimnames(out) = list(NULL, c("Age","Experience",
"Income","Family",
"CCAvg","Mortgage",
"Securities.Account",
"CD.Account","Online",
"CreditCard","Education1",
"Education2","Education3",
"nn_Output"))
head(out)
rm(out)
nn
plot(nn)
predicted = factor(ifelse(nn$net.result[[1]] > 0.5, 1, 0))
conf_Matrix = table(train_Data$Personal.Loan, predicted)
recall = (conf_Matrix[2,2] / (conf_Matrix[2,1] + conf_Matrix[2,2])) * 100
recall
rm(predicted, conf_Matrix, recall)
test_Data_No_Target = subset(test_Data, select=-c(Personal.Loan))
nn_predict = compute(nn, covariate= test_Data_No_Target)
rm(test_Data_No_Target)
nn_predict$net.result
predicted = factor(ifelse(nn_predict$net.result > 0.5, 1, 0))
conf_Matrix = table(test_Data$Personal.Loan, predicted)
recall = (conf_Matrix[2,2]/(conf_Matrix[2,1]+conf_Matrix[2,2]))*100
recall
rm(nn_predict, predicted, conf_Matrix, recall)
rm(test_Data, train_Data, nn)
rm(list=ls(all=TRUE))
setwd("D:/naveen/Bigdata - hadoop and related/ActivitiesRepo/20161225_Batch22_CSE7405c_NeuralNetLab/20161225_CSE7405c_Batch22_NeuralNetLab")
library(neuralnet)
